{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f51d2898",
   "metadata": {},
   "source": [
    "**DESCRIPTION:** This model will run a regression on all of the data over the time period given, treating identifier, market cap, the factors, etc as independent variables. \n",
    "The regression is completed using SKLearn which utilizes test and training data to fit a learned model to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7532985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from time import time\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815f197e",
   "metadata": {},
   "source": [
    "**Calculating the Model:** The function below calculates and plots our model given a datatable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932d1f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_model(data, predictor_list):\n",
    "    # Sets the index of the graph as the date so that the regression occurs\n",
    "    # over the dates\n",
    "    df.set_index(pd.DatetimeIndex(df['date']), inplace=True)\n",
    "\n",
    "    # Sets the  predictor values\n",
    "    predictors = predictor_list\n",
    "\n",
    "    # Uses the train_test_split to randomly select 30% of the data as testing\n",
    "    # data and saving the rest for the creation/training of the model\n",
    "    train, test = train_test_split(data, test_size=0.3)\n",
    "\n",
    "    # Defines the model as a Linear Regression\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Fits the model using the predictors above and defined target training data\n",
    "    model.fit(train[predictors], train[\"target\"])\n",
    "\n",
    "    # Creates the predictors using the model.predict\n",
    "    preds = model.predict(test[predictors])\n",
    "    preds = pd.Series(preds, index=test.index)\n",
    "\n",
    "    # Calculates the r^2 score based on the test values and the predicted values\n",
    "    r = r2_score(test[\"target\"], preds)\n",
    "\n",
    "    combined = pd.concat({\"target\": test[\"target\"], \"Predictions\": preds},\n",
    "                         axis=1)\n",
    "\n",
    "    # k_fold test\n",
    "    # predictor (x) and response variables (y)\n",
    "    y = data['target']\n",
    "    X = data[predictor_list]\n",
    "\n",
    "    # Conducts the K_Fold test\n",
    "    cv = KFold(n_splits=10, random_state=100, shuffle=True)\n",
    "\n",
    "    # modl = LinearRegression()\n",
    "\n",
    "    # Calculates the cross validation score which is later used to calculate the\n",
    "    # RMSE below\n",
    "    scores = cross_val_score(model, train[predictors], train[\"target\"],\n",
    "                             scoring='neg_mean_absolute_error',\n",
    "                             cv=cv, n_jobs=-1)\n",
    "    \n",
    "    # the lower the RMSE the better\n",
    "    print(\"r^2 is = \" + str(r))\n",
    "    print(\"root mean squared error (RMSE) = \" + str(np.sqrt(np.mean(np.absolute(\n",
    "        scores)))))\n",
    "\n",
    "    features = ['sector','market_cap', 'index_membership', 'factor_1',\n",
    "                'factor_2', 'factor_3', 'factor_4', 'factor_5', 'factor_6',\n",
    "                'factor_7', 'factor_8', 'factor_9', 'factor_10']\n",
    "        \n",
    "    ridge = RidgeCV(alphas = np.logspace(-6, 6, num=5)).fit(X, y)\n",
    "        \n",
    "    # Visualizing Feature Importance\n",
    "        \n",
    "    feature_importance(X, y, ridge)\n",
    "        \n",
    "    #Selecting features with Sequential Feature SelectionÂ¶\n",
    "        \n",
    "    seq_selection(X, y, features, ridge)\n",
    "        \n",
    "    #Tuning(test, train, predictors, model, preds)\n",
    "    \n",
    "    \n",
    "    # Plots the origional vs predicted\n",
    "    combined.plot()\n",
    "    plt.title(\"Full Model\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e22bb0",
   "metadata": {},
   "source": [
    "**Feature Importance of Coefficients using RidgeCV:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52eb7734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple helper function to go from list of True and False to the final selected values\n",
    "\n",
    "def selecting(lst, features):\n",
    "    selected = []\n",
    "    for i in range(0,13):\n",
    "        if lst[i] == True:\n",
    "            selected.append(features[i])\n",
    "    return selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ef75ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance(X, y, ridge):\n",
    "        \n",
    "    importance = list(np.abs(ridge.coef_))\n",
    "\n",
    "    features = ['sector','market \\n cap', 'index \\n membership', 'factor_1',\n",
    "            'factor_2', 'factor_3', 'factor_4', 'factor_5', 'factor_6',\n",
    "            'factor_7', 'factor_8', 'factor_9', 'factor_10']\n",
    "\n",
    "    dta = {}\n",
    "    importance_2 = []\n",
    "    \n",
    "    for i in range(0,13):\n",
    "        importance_2.append(importance[i] *1000)\n",
    "        dta[features[i]] = importance_2[i]\n",
    "\n",
    "    names = list(dta.keys())\n",
    "    values = list(dta.values())\n",
    "\n",
    "    fig, axs = plt.subplots(1, 1, figsize=(16, 3), sharey=True)\n",
    "    plt.bar(names, values)\n",
    "    fig.suptitle('Feature importances via coefficients (scaled by 1000)')\n",
    "\n",
    "    # Selecting features based on importance\n",
    "    \n",
    "    threshold = np.sort(importance)[-3] + 0.01\n",
    "    tic = time()\n",
    "    sfm = SelectFromModel(ridge, threshold=threshold).fit(X, y)\n",
    "    toc = time()\n",
    "    lst = list(sfm.get_support())\n",
    "    print(f\"Features selected by SelectFromModel:\", selecting(lst, features))\n",
    "    print(f\"Done in {toc - tic:.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056b2f19",
   "metadata": {},
   "source": [
    "**Selecting features with Sequential Feature Selection:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc11831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_selection(X, y, features, ridge):\n",
    "\n",
    "    tic_fwd = time()\n",
    "    sfs_forward = SequentialFeatureSelector(\n",
    "        ridge, n_features_to_select=2, direction=\"forward\"\n",
    "    ).fit(X, y)\n",
    "    toc_fwd = time()\n",
    "\n",
    "    tic_bwd = time()\n",
    "    sfs_backward = SequentialFeatureSelector(\n",
    "        ridge, n_features_to_select=2, direction=\"backward\"\n",
    "    ).fit(X, y)\n",
    "    toc_bwd = time()\n",
    "\n",
    "    print(\n",
    "        \"Features selected by forward sequential selection: \", selecting(sfs_forward.get_support(), features)\n",
    "    )\n",
    "    print(f\"Done in {toc_fwd - tic_fwd:.3f}s\")\n",
    "    print(\n",
    "        \"Features selected by backward sequential selection: \", selecting(sfs_backward.get_support(), features)\n",
    "    )\n",
    "    print(f\"Done in {toc_bwd - tic_bwd:.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f421a0",
   "metadata": {},
   "source": [
    "**Note on Path to File:** Below I have specified the path to the given CSV containing the data. You do not need to change the path for it to work on this notebook, but if you would like to download the code, you may."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cb173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = \"data/data.csv\"\n",
    "\n",
    "# Reads the information contained in the CSV\n",
    "df = pd.read_csv(path_to_file)\n",
    "\n",
    "# Turns the identifiers into dummy variables for the regression\n",
    "df = pd.get_dummies(df,prefix='Identifier ', prefix_sep='=', columns=[\n",
    "    'identifier'])\n",
    "\n",
    "# Setting the list predictor variables called cols\n",
    "cols = list(df.columns)\n",
    "\n",
    "cols.remove('target')\n",
    "cols.remove('date')\n",
    "\n",
    "# Running the regression with the given dataset and predictor list\n",
    "calculate_model(df, cols)\n",
    "\n",
    "print('\\n Model Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7d62c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
